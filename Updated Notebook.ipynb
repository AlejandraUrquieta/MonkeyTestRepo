{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "526b8b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18313\\MonkeyTestRepo\\motionmapperpyOther\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing motionmapperpy.egg-info\\PKG-INFO\n",
      "writing dependency_links to motionmapperpy.egg-info\\dependency_links.txt\n",
      "writing requirements to motionmapperpy.egg-info\\requires.txt\n",
      "writing top-level names to motionmapperpy.egg-info\\top_level.txt\n",
      "reading manifest file 'motionmapperpy.egg-info\\SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'motionmapperpy.egg-info\\SOURCES.txt'\n",
      "installing library code to build\\bdist.win-amd64\\egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\\bdist.win-amd64\\egg\n",
      "creating build\\bdist.win-amd64\\egg\\motionmapperpy\n",
      "copying build\\lib\\motionmapperpy\\mmutils.py -> build\\bdist.win-amd64\\egg\\motionmapperpy\n",
      "copying build\\lib\\motionmapperpy\\motionmapper.py -> build\\bdist.win-amd64\\egg\\motionmapperpy\n",
      "copying build\\lib\\motionmapperpy\\setrunparameters.py -> build\\bdist.win-amd64\\egg\\motionmapperpy\n",
      "copying build\\lib\\motionmapperpy\\wavelet.py -> build\\bdist.win-amd64\\egg\\motionmapperpy\n",
      "copying build\\lib\\motionmapperpy\\wshed.py -> build\\bdist.win-amd64\\egg\\motionmapperpy\n",
      "copying build\\lib\\motionmapperpy\\__init__.py -> build\\bdist.win-amd64\\egg\\motionmapperpy\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\motionmapperpy\\mmutils.py to mmutils.cpython-39.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\motionmapperpy\\motionmapper.py to motionmapper.cpython-39.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\motionmapperpy\\setrunparameters.py to setrunparameters.cpython-39.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\motionmapperpy\\wavelet.py to wavelet.cpython-39.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\motionmapperpy\\wshed.py to wshed.cpython-39.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\motionmapperpy\\__init__.py to __init__.cpython-39.pyc\n",
      "creating build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying motionmapperpy.egg-info\\PKG-INFO -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying motionmapperpy.egg-info\\SOURCES.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying motionmapperpy.egg-info\\dependency_links.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying motionmapperpy.egg-info\\requires.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying motionmapperpy.egg-info\\top_level.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "creating 'dist\\motionmapperpy-1.0-py3.9.egg' and adding 'build\\bdist.win-amd64\\egg' to it\n",
      "removing 'build\\bdist.win-amd64\\egg' (and everything under it)\n",
      "Processing motionmapperpy-1.0-py3.9.egg\n",
      "Removing c:\\users\\18313\\anaconda3\\lib\\site-packages\\motionmapperpy-1.0-py3.9.egg\n",
      "C:\\Users\\18313\\MonkeyTestRepo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18313\\anaconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "C:\\Users\\18313\\anaconda3\\lib\\site-packages\\setuptools\\command\\easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "error: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\users\\\\18313\\\\anaconda3\\\\lib\\\\site-packages\\\\motionmapperpy-1.0-py3.9.egg'\n"
     ]
    }
   ],
   "source": [
    "%cd motionmapperpyOther\n",
    "\n",
    "!python setup.py install\n",
    "\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24625779",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54d05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import glob, os, sys\n",
    "\n",
    "import time, copy\n",
    "from datetime import datetime\n",
    "import hdf5storage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "from pythonlib.dataset.dataset import Dataset\n",
    "from pythonlib.dataset.dataset_preprocess.general import preprocessDat\n",
    "\n",
    "import motionmapperpy as mmpy\n",
    "\n",
    "from pythonlib.tools.expttools import makeTimeStamp, writeDictToYaml\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#add these to testMonkey1\n",
    "from IPython.display import Image\n",
    "import random\n",
    "from pythonlib.drawmodel import strokePlots\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8890d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = makeTimeStamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9195521f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating : content/trial1_mmpy220721_122012\n",
      "Creating : content/trial1_mmpy220721_122012/Projections\n",
      "Creating : content/trial1_mmpy220721_122012/TSNE_Projections\n",
      "Creating : content/trial1_mmpy220721_122012/TSNE\n",
      "Creating : content/trial1_mmpy220721_122012/UMAP\n"
     ]
    }
   ],
   "source": [
    "projectPath = f'content/trial1_mmpy{ts}'\n",
    "\n",
    "# This creates a project directory structure which will be used to store all motionmappery pipeline\n",
    "# related data in one place.\n",
    "\n",
    "mmpy.createProjectDirectory(projectPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91377fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea2996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = 'gridlinecircle'\n",
    "path_list = [\n",
    "    \"data_030421/Pancho-gridlinecircle-baseline-210824_002447\",\n",
    "    \"data_030421/Pancho-gridlinecircle-circletoline-210828_100027\",\n",
    "    \"data_030421/Pancho-gridlinecircle-linetocircle-210828_100152\",\n",
    "    \"data_030421/Pancho-gridlinecircle-lolli-210903_094051\",\n",
    "]\n",
    "append_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e217b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = mmpy.setRunParameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b7655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%%%%% PARAMETERS TO CHANGE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# These need to be revised everytime you are working with a new dataset. #\n",
    "\n",
    "parameters.projectPath = projectPath #% Full path to the project directory.\n",
    "\n",
    "\n",
    "#parameters.method = 'UMAP' #% We can choose between 'TSNE' or 'UMAP'\n",
    "\n",
    "parameters.minF = 1        #% Minimum frequency for Morlet Wavelet Transform\n",
    "\n",
    "parameters.maxF = 25       #% Maximum frequency for Morlet Wavelet Transform,\n",
    "                           #% usually equal to the Nyquist frequency for your\n",
    "                           #% measurements.\n",
    "\n",
    "parameters.samplingFreq = 100    #% Sampling frequency (or FPS) of data.\n",
    "\n",
    "parameters.numPeriods = 25       #% No. of dyadically spaced frequencies to\n",
    "                                 #% calculate between minF and maxF.\n",
    "comps_above_thresh = 2\n",
    "parameters.pcaModes = comps_above_thresh #% Number of low-d features.\n",
    "\n",
    "parameters.numProcessors = -1     #% No. of processor to use when parallel\n",
    "                                 #% processing for wavelet calculation (if not using GPU)  \n",
    "                                 #% and for re-embedding. -1 to use all cores \n",
    "                                 #% available.\n",
    "\n",
    "parameters.useGPU = -1           #% GPU to use for wavelet calculation, \n",
    "                                 #% set to -1 if GPU not present.\n",
    "\n",
    "parameters.training_numPoints = 10000   #% Number of points in mini-trainings.\n",
    "\n",
    "\n",
    "# %%%%% NO NEED TO CHANGE THESE UNLESS MEMORY ERRORS OCCUR %%%%%%%%%%\n",
    "\n",
    "parameters.trainingSetSize = 5000  #% Total number of training set points to find. \n",
    "                                 #% Increase or decrease based on\n",
    "                                 #% available RAM. For reference, 36k is a \n",
    "                                 #% good number with 64GB RAM.\n",
    "\n",
    "parameters.embedding_batchSize = 30000  #% Lower this if you get a memory error when \n",
    "                                        #% re-embedding points on a learned map.\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# %%%%%%% tSNE parameters %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "#% can be 'barnes_hut' or 'exact'. We'll use barnes_hut for this tutorial for speed.\n",
    "parameters.tSNE_method = 'barnes_hut' \n",
    "\n",
    "# %2^H (H is the transition entropy)\n",
    "parameters.perplexity = 32\n",
    "\n",
    "# %number of neigbors to use when re-embedding\n",
    "parameters.maxNeighbors = 200\n",
    "\n",
    "# %local neighborhood definition in training set creation\n",
    "parameters.kdNeighbors = 5\n",
    "\n",
    "# %t-SNE training set perplexity\n",
    "parameters.training_perplexity = 20\n",
    "\n",
    "writeDictToYaml(parameters, projectPath+'/parameters.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13121ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add this line to see stuff from other files\n",
    "#parameters.projectPath = 'content/trial1_mmpyFROMSERVER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "704d636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get data in the form of array dataTotal\n",
    "def get_dataTotal(D):\n",
    "    # x is the trial index there are 5125 trials so x < 5125\n",
    "    x = 0\n",
    "    # y is the stroke index- we dont know how many strokes r there\n",
    "    y = 0\n",
    "    # i is the index of one time frame of one stroke, \n",
    "    # this index also varies for each trial and stroke\n",
    "    i = 0\n",
    "    #ldataOneStroke = np.array([])\n",
    "    #dataTotal = np.empty([150,1])\n",
    "    ldataOneStroke = []\n",
    "    ldataOneTrial = []\n",
    "    ldataTotal = []\n",
    "    #len(D.Dat)\n",
    "    x=0\n",
    "    for x in range(len(D.Dat)):\n",
    "        y=0\n",
    "        ldataOneTrial = []\n",
    "        for y in range(len(D.Dat.iloc[x][\"strokes_beh\"])):\n",
    "            #print(len(D.Dat.iloc[x][\"strokes_beh\"]))\n",
    "            i=0\n",
    "            ldataOneStroke = []\n",
    "            for i in range(i,len(D.Dat.iloc[x][\"strokes_beh\"][y])):\n",
    "                temp = D.Dat.iloc[x][\"strokes_beh\"][y][i][0:2]\n",
    "                ldataOneStroke.append(temp)\n",
    "            #print(len(ldataOneStroke))\n",
    "            dataOneStroke = np.array(ldataOneStroke)\n",
    "            #print(dataOneStroke)\n",
    "            #ldataOneTrial = np.append(ldataOneTrial,ldataOneStroke)\n",
    "            ldataOneTrial.append(dataOneStroke)\n",
    "        #print(len(ldataOneTrial))    \n",
    "        dataOneTrial = np.array(ldataOneTrial)\n",
    "        ldataTotal.append(dataOneTrial)\n",
    "        #ldataTotal = np.append(ldataTotal,ldataOneTrial)\n",
    "        #dataOneTrial = np.vstack((dataOneTrial, dataOneStroke))\n",
    "    dataTotal = np.array(ldataTotal)\n",
    "    return dataTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da92b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get list of strokes indexes\n",
    "def get_strokeIndexes(dataTotal):\n",
    "    list_trialstroke = []\n",
    "    for trial, x in enumerate(dataTotal):\n",
    "        #print(len(x))\n",
    "        for strokenum, xx in enumerate(x):\n",
    "            list_trialstroke.append((trial, strokenum))\n",
    "    return list_trialstroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b551e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get list of \n",
    "# num should not be more than 5125\n",
    "def get_strokes(dataTotal,num):\n",
    "    #ndata = len(dataTotal)\n",
    "    ndata = num\n",
    "\n",
    "    lindependentStrokes = []\n",
    "    for x in range(ndata):\n",
    "        for y in range(len(dataTotal[x])):\n",
    "            temp = dataTotal[x][y]\n",
    "            lindependentStrokes.append(temp)\n",
    "    #independentStrokes = np.array(lindependentStrokes)\n",
    "    return lindependentStrokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "165dc111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_tsne(parameters):\n",
    "    mmpy.subsampled_tsne_from_projections(parameters, parameters.projectPath)\n",
    "    #print(\"HERE1\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c27f13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_tsne(parameters):\n",
    "    #tsne takes 19 mins\n",
    "    tall = time.time()\n",
    "\n",
    "    import h5py\n",
    "    tfolder = parameters.projectPath+'/%s/'%parameters.method\n",
    "\n",
    "    # Loading training data\n",
    "    with h5py.File(tfolder + 'training_data.mat', 'r') as hfile:\n",
    "        trainingSetData = hfile['trainingSetData'][:].T\n",
    "\n",
    "    # Loading training embedding\n",
    "    with h5py.File(tfolder+ 'training_embedding.mat', 'r') as hfile:\n",
    "        trainingEmbedding= hfile['trainingEmbedding'][:].T\n",
    "\n",
    "    if parameters.method == 'TSNE':\n",
    "        zValstr = 'zVals' \n",
    "    else:\n",
    "        zValstr = 'uVals'\n",
    "\n",
    "\n",
    "\n",
    "    projectionFiles = glob.glob(parameters.projectPath+'/Projections/*notpca.mat')\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(projectionFiles)):\n",
    "        print('Finding Embeddings')\n",
    "        t1 = time.time()\n",
    "        print('%i/%i : %s'%(i+1,len(projectionFiles), projectionFiles[i]))\n",
    "\n",
    "\n",
    "        # Skip if embeddings already found.\n",
    "        if os.path.exists(projectionFiles[i][:-4] +'_%s.mat'%(zValstr)):\n",
    "            print('Already done. Skipping.\\n')\n",
    "            continue\n",
    "\n",
    "        # load projections for a dataset\n",
    "        #modifying adding np.array\n",
    "        projections = np.array(hdf5storage.loadmat(projectionFiles[i])['projections'])\n",
    "\n",
    "        # Find Embeddings\n",
    "        zValues, outputStatistics = mmpy.findEmbeddings(projections,trainingSetData,trainingEmbedding,parameters)\n",
    "\n",
    "        # Save embeddings\n",
    "        hdf5storage.write(data = {'zValues':zValues}, path = '/', truncate_existing = True,\n",
    "                        filename = projectionFiles[i][:-4]+'_%s.mat'%(zValstr), store_python_metadata = False,\n",
    "                          matlab_compatible = True)\n",
    "\n",
    "        # Save output statistics\n",
    "        with open(projectionFiles[i][:-4] + '_%s_outputStatistics.pkl'%(zValstr), 'wb') as hfile:\n",
    "            pickle.dump(outputStatistics, hfile)\n",
    "\n",
    "        del zValues,projections,outputStatistics\n",
    "\n",
    "\n",
    "    print('All Embeddings Saved in %i seconds!'%(time.time()-tall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e44d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Currently loading: data_030421/Pancho-gridlinecircle-baseline-210824_002447\n",
      "Loaded metadat:\n",
      "{'sketchpad_edges': array([[-311.84, -224.8 ],\n",
      "       [ 311.84,  429.6 ]]), 'metadat_probedat': {'sdate': 210820, 'edate': 210821, 'strokmodel_kind': None, 'strokmodel_tstamp': None, 'datecategories': {'210820': 1, '210821': 1}, 'dates_for_summary': [], 'matchedstrokes': None, 'exptnames': ['gridlinecircle1', 'gridlinecircle2'], 'T1': [], 'G1': [], 'G2': [], 'G3': [], 'G4': [], 'description': '', 'finalized': False, 'good_expt': True, 'expt': 'gridlinecircle', 'task_train_test': {'probe1_liketrain': 'train', 'probe1_nostrokeconstraint': 'train', 'probe2_liketrain': 'train', 'probe2_nostrokeconstraint': 'train', 'probe3_hdpos': 'test', 'probe1': 'train', 'probe2': 'train', 'probe3': 'test', 'probe4': 'test', 'train': 'train'}}, 'filedata_params': {'pix_per_deg': array([[ 26.64621164],\n",
      "       [-26.64621164]]), 'resolution': (1024, 768), 'animal': 'Pancho', 'basedir': '/data2/animals', 'sample_rate': array([125.]), 'beh_codes': {9: 'start', 10: 'fix cue', 11: 'fix cue visible', 13: 'frame skip', 14: 'manual rew', 15: 'guide', 16: 'FixationOnsetWTH', 17: 'FixationDoneSuccessWTH', 19: 'FixationRaiseFailWTH', 18: 'end', 20: 'go (draw)', 21: 'guide_on_GA', 41: 'samp1 on', 42: 'samp1 off', 45: 'done', 46: 'post', 50: 'reward', 51: 'free reward', 61: 'DoneButtonVisible', 62: 'DoneButtonTouched', 63: 'DragAroundSuccess', 70: 'hotkey_x'}, 'screen_hz': 60, 'screen_period': 0.016666666666666666}}\n",
      "----------------\n",
      "Currently loading: data_030421/Pancho-gridlinecircle-circletoline-210828_100027\n",
      "Loaded metadat:\n",
      "{'sketchpad_edges': array([[-311.84, -224.8 ],\n",
      "       [ 311.84,  429.6 ]]), 'metadat_probedat': {'sdate': 210824, 'edate': 210827, 'strokmodel_kind': None, 'strokmodel_tstamp': None, 'datecategories': {'210824': 1, '210825': 1, '210826': 1, '210827': 1}, 'dates_for_summary': [], 'matchedstrokes': None, 'exptnames': ['gridlinecircle1', 'gridlinecircle2'], 'T1': [], 'G1': [], 'G2': [], 'G3': [], 'G4': [], 'description': '', 'finalized': False, 'good_expt': True, 'expt': 'gridlinecircle', 'task_train_test': {'probe1_liketrain': 'train', 'probe1_nostrokeconstraint': 'train', 'probe2_liketrain': 'train', 'probe2_nostrokeconstraint': 'train', 'probe3_hdpos': 'test', 'probe1': 'train', 'probe2': 'train', 'probe3': 'test', 'probe4': 'test', 'train': 'train'}}, 'filedata_params': {'pix_per_deg': array([[ 26.64621164],\n",
      "       [-26.64621164]]), 'resolution': (1024, 768), 'animal': 'Pancho', 'basedir': '/data2/animals', 'sample_rate': array([125.]), 'beh_codes': {9: 'start', 10: 'fix cue', 11: 'fix cue visible', 13: 'frame skip', 14: 'manual rew', 15: 'guide', 16: 'FixationOnsetWTH', 17: 'FixationDoneSuccessWTH', 19: 'FixationRaiseFailWTH', 18: 'end', 20: 'go (draw)', 21: 'guide_on_GA', 41: 'samp1 on', 42: 'samp1 off', 45: 'done', 46: 'post', 50: 'reward', 51: 'free reward', 61: 'DoneButtonVisible', 62: 'DoneButtonTouched', 63: 'DragAroundSuccess', 70: 'hotkey_x'}, 'screen_hz': 60, 'screen_period': 0.016666666666666666}}\n",
      "----------------\n",
      "Currently loading: data_030421/Pancho-gridlinecircle-linetocircle-210828_100152\n",
      "Loaded metadat:\n",
      "{'sketchpad_edges': array([[-311.84, -224.8 ],\n",
      "       [ 311.84,  429.6 ]]), 'metadat_probedat': {'sdate': 210822, 'edate': 210823, 'strokmodel_kind': None, 'strokmodel_tstamp': None, 'datecategories': {'210822': 1, '210823': 1}, 'dates_for_summary': [], 'matchedstrokes': None, 'exptnames': ['gridlinecircle1', 'gridlinecircle2'], 'T1': [], 'G1': [], 'G2': [], 'G3': [], 'G4': [], 'description': '', 'finalized': False, 'good_expt': True, 'expt': 'gridlinecircle', 'task_train_test': {'probe1_liketrain': 'train', 'probe1_nostrokeconstraint': 'train', 'probe2_liketrain': 'train', 'probe2_nostrokeconstraint': 'train', 'probe3_hdpos': 'test', 'probe1': 'train', 'probe2': 'train', 'probe3': 'test', 'probe4': 'test', 'train': 'train'}}, 'filedata_params': {'pix_per_deg': array([[ 26.64621164],\n",
      "       [-26.64621164]]), 'resolution': (1024, 768), 'animal': 'Pancho', 'basedir': '/data2/animals', 'sample_rate': array([125.]), 'beh_codes': {9: 'start', 10: 'fix cue', 11: 'fix cue visible', 13: 'frame skip', 14: 'manual rew', 15: 'guide', 16: 'FixationOnsetWTH', 17: 'FixationDoneSuccessWTH', 19: 'FixationRaiseFailWTH', 18: 'end', 20: 'go (draw)', 21: 'guide_on_GA', 41: 'samp1 on', 42: 'samp1 off', 45: 'done', 46: 'post', 50: 'reward', 51: 'free reward', 61: 'DoneButtonVisible', 62: 'DoneButtonTouched', 63: 'DragAroundSuccess', 70: 'hotkey_x'}, 'screen_hz': 60, 'screen_period': 0.016666666666666666}}\n",
      "----------------\n",
      "Currently loading: data_030421/Pancho-gridlinecircle-lolli-210903_094051\n",
      "Loaded metadat:\n",
      "{'sketchpad_edges': array([[-311.84, -224.8 ],\n",
      "       [ 311.84,  429.6 ]]), 'metadat_probedat': {'sdate': 210828, 'edate': 210902, 'strokmodel_kind': None, 'strokmodel_tstamp': None, 'datecategories': {'210828': 1, '210829': 1, '210830': 1, '210831': 1, '210901': 1, '210902': 1}, 'dates_for_summary': [], 'matchedstrokes': None, 'exptnames': ['gridlinecircle1', 'gridlinecircle2'], 'T1': [], 'G1': [], 'G2': [], 'G3': [], 'G4': [], 'description': '', 'finalized': False, 'good_expt': True, 'expt': 'gridlinecircle', 'task_train_test': {'probe1_liketrain': 'train', 'probe1_nostrokeconstraint': 'train', 'probe2_liketrain': 'train', 'probe2_nostrokeconstraint': 'train', 'probe3_hdpos': 'test', 'probe1': 'train', 'probe2': 'train', 'probe3': 'test', 'probe4': 'test', 'train': 'train'}}, 'filedata_params': {'pix_per_deg': array([[ 26.64621164],\n",
      "       [-26.64621164]]), 'resolution': (1024, 768), 'animal': 'Pancho', 'basedir': '/data2/animals', 'sample_rate': array([125.]), 'beh_codes': {9: 'start', 10: 'fix cue', 11: 'fix cue visible', 13: 'frame skip', 14: 'manual rew', 15: 'guide', 16: 'FixationOnsetWTH', 17: 'FixationDoneSuccessWTH', 19: 'FixationRaiseFailWTH', 18: 'end', 20: 'go (draw)', 21: 'guide_on_GA', 41: 'samp1 on', 42: 'samp1 off', 45: 'done', 46: 'post', 50: 'reward', 51: 'free reward', 61: 'DoneButtonVisible', 62: 'DoneButtonTouched', 63: 'DragAroundSuccess', 70: 'hotkey_x'}, 'screen_hz': 60, 'screen_period': 0.016666666666666666}}\n",
      "----\n",
      "Resetting index\n",
      "=== CLEANING UP self.Dat ===== \n",
      "Deleted unused columns from self.Dat\n",
      "applying monkey train test names\n",
      "resetting index\n",
      "Removed online aborts\n",
      "Updated columns: insummarydates, using Metadats\n"
     ]
    }
   ],
   "source": [
    "D = Dataset(path_list, append_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad3b1c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18313\\AppData\\Local\\Temp\\ipykernel_47640\\4208463306.py:33: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataOneTrial = np.array(ldataOneTrial)\n",
      "C:\\Users\\18313\\AppData\\Local\\Temp\\ipykernel_47640\\4208463306.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataTotal = np.array(ldataTotal)\n"
     ]
    }
   ],
   "source": [
    "dataTotal = get_dataTotal(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca411ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_trialstroke = get_strokeIndexes(dataTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03840d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = get_strokes(dataTotal,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea9e4b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content/trial1_mmpy220721_122012/Projections/test_monkey_notpca.mat\n"
     ]
    }
   ],
   "source": [
    "print('%s/Projections/test_monkey_notpca.mat'%(projectPath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fd78f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5storage.savemat('%s/Projections/test_monkey_notpca.mat'%(projectPath), {\"projections\" : projections})\n",
    "\n",
    "#projectionFiles = glob.glob(parameters.projectPath+'/Projections/*test_monkey_notPCA.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0a5649d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numProcessors': -1,\n",
       " 'numPeriods': 25,\n",
       " 'omega0': 5,\n",
       " 'samplingFreq': 100,\n",
       " 'minF': 1,\n",
       " 'maxF': 25,\n",
       " 'tSNE_method': 'barnes_hut',\n",
       " 'perplexity': 32,\n",
       " 'embedding_batchSize': 30000,\n",
       " 'maxOptimIter': 100,\n",
       " 'trainingSetSize': 5000,\n",
       " 'maxNeighbors': 200,\n",
       " 'kdNeighbors': 5,\n",
       " 'training_perplexity': 20,\n",
       " 'training_numPoints': 10000,\n",
       " 'minTemplateLength': 1,\n",
       " 'waveletDecomp': True,\n",
       " 'useGPU': -1,\n",
       " 'n_neighbors': 15,\n",
       " 'train_negative_sample_rate': 5,\n",
       " 'embed_negative_sample_rate': 1,\n",
       " 'min_dist': 0.1,\n",
       " 'umap_output_dims': 2,\n",
       " 'n_training_epochs': 1000,\n",
       " 'rescale_max': 100,\n",
       " 'method': 'TSNE',\n",
       " 'projectPath': 'content/trial1_mmpy220721_122012',\n",
       " 'pcaModes': 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c87107c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Training Set\n",
      "5000\n",
      "10000\n",
      "Finding training set contributions from data set 1/1 : \n",
      "content/trial1_mmpy220721_122012/Projections\\test_monkey_notpca.mat\n",
      "\t Loading Projections\n",
      "test\n",
      "\t Calculating Wavelets\n",
      "\t Calculating wavelets, clock starting.\n",
      "\t Using #12 CPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18313\\MonkeyTestRepo\\motionmapperpy\\motionmapper.py:218: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  projections_in = np.array(mat73.loadmat(projectionFile)[\"projections\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Done at 6.72 seconds.\n",
      "17\n",
      "71\n",
      "51\n",
      "20\n",
      "\t Calculating Wavelets\n",
      "\t Calculating wavelets, clock starting.\n",
      "\t Using #12 CPUs.\n",
      "\t Done at 6.77 seconds.\n",
      "19\n",
      "78\n",
      "57\n",
      "21\n",
      "\t Calculating Wavelets\n",
      "\t Calculating wavelets, clock starting.\n",
      "\t Using #12 CPUs.\n",
      "\t Done at 6.66 seconds.\n",
      "20\n",
      "82\n",
      "60\n",
      "22\n",
      "\t Calculating Wavelets\n",
      "\t Calculating wavelets, clock starting.\n",
      "\t Using #12 CPUs.\n",
      "\t Done at 6.45 seconds.\n",
      "19\n",
      "77\n",
      "57\n",
      "20\n",
      "\t Calculating Wavelets\n",
      "\t Calculating wavelets, clock starting.\n",
      "\t Using #12 CPUs.\n",
      "\t Done at 6.67 seconds.\n",
      "20\n",
      "80\n",
      "60\n",
      "20\n",
      "Finding Distances\n",
      "Computing t-SNE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18313\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\18313\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\18313\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:819: FutureWarning: 'square_distances' has been introduced in 0.24 to help phase out legacy squaring behavior. The 'legacy' setting will be removed in 1.1 (renaming of 0.26), and the default setting will be changed to True. In 1.3, 'square_distances' will be removed altogether, and distances will be squared by default. Set 'square_distances'=True to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 2 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msub_tsne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36msub_tsne\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub_tsne\u001b[39m(parameters):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmmpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubsampled_tsne_from_projections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprojectPath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\MonkeyTestRepo\\motionmapperpy\\motionmapper.py:453\u001b[0m, in \u001b[0;36msubsampled_tsne_from_projections\u001b[1;34m(parameters, results_directory)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinding Training Set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(tsne_directory\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_data.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 453\u001b[0m     trainingSetData,trainingSetAmps,_ \u001b[38;5;241m=\u001b[39m \u001b[43mrunEmbeddingSubSampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprojection_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(tsne_directory):\n\u001b[0;32m    455\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mrmtree(tsne_directory)\n",
      "File \u001b[1;32m~\\MonkeyTestRepo\\motionmapperpy\\motionmapper.py:410\u001b[0m, in \u001b[0;36mrunEmbeddingSubSampling\u001b[1;34m(projectionDirectory, parameters)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinding training set contributions from data set \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, L, projectionFiles[i]))\n\u001b[0;32m    408\u001b[0m currentIdx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(numPerDataSet) \u001b[38;5;241m+\u001b[39m (i \u001b[38;5;241m*\u001b[39m numPerDataSet)\n\u001b[1;32m--> 410\u001b[0m yData, signalData, _, signalAmps \u001b[38;5;241m=\u001b[39m \u001b[43mfile_embeddingSubSampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprojectionFiles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m trainingSetData[currentIdx,:], trainingSetAmps[currentIdx] \u001b[38;5;241m=\u001b[39m findTemplatesFromData(signalData, yData,\n\u001b[0;32m    413\u001b[0m                                                                                    signalAmps, numPerDataSet,\n\u001b[0;32m    414\u001b[0m                                                                                 parameters,projectionFiles[i])\n\u001b[0;32m    416\u001b[0m a \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39msum(trainingSetData[currentIdx,:], \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\MonkeyTestRepo\\motionmapperpy\\motionmapper.py:322\u001b[0m, in \u001b[0;36mfile_embeddingSubSampling\u001b[1;34m(projectionFile, parameters)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSNE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    321\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m=\u001b[39m perplexity\n\u001b[1;32m--> 322\u001b[0m     yData \u001b[38;5;241m=\u001b[39m \u001b[43mrun_tSne\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignalData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUMAP\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    324\u001b[0m     yData \u001b[38;5;241m=\u001b[39m run_UMAP(signalData, parameters, save_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\MonkeyTestRepo\\motionmapperpy\\motionmapper.py:96\u001b[0m, in \u001b[0;36mrun_tSne\u001b[1;34m(data, parameters)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing t-SNE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m     tsne \u001b[38;5;241m=\u001b[39m TSNE(perplexity\u001b[38;5;241m=\u001b[39mparameters\u001b[38;5;241m.\u001b[39mperplexity, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     95\u001b[0m                 method\u001b[38;5;241m=\u001b[39mparameters\u001b[38;5;241m.\u001b[39mtSNE_method)\n\u001b[1;32m---> 96\u001b[0m     yData \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     98\u001b[0m     tsne \u001b[38;5;241m=\u001b[39m TSNE(perplexity\u001b[38;5;241m=\u001b[39mparameters\u001b[38;5;241m.\u001b[39mperplexity, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     99\u001b[0m                 method\u001b[38;5;241m=\u001b[39mparameters\u001b[38;5;241m.\u001b[39mtSNE_method)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1108\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \n\u001b[0;32m   1091\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1108\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[0;32m   1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:830\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    819\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquare_distances\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been introduced in 0.24 to help phase \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout legacy squaring behavior. The \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegacy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m setting will be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    827\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    828\u001b[0m     )\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarnes_hut\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 830\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    837\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    838\u001b[0m         X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat32, np\u001b[38;5;241m.\u001b[39mfloat64]\n\u001b[0;32m    839\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:805\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    809\u001b[0m         )\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    812\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 2 is required."
     ]
    }
   ],
   "source": [
    "sub_tsne(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = hdf5storage.loadmat('%s/%s/training_embedding.mat'%(parameters.projectPath, parameters.method))['trainingEmbedding']\n",
    "m = np.abs(trainy).max()\n",
    "\n",
    "\n",
    "sigma=2.0\n",
    "_, xx, density = mmpy.findPointDensity(trainy, sigma, 511, [-m-20, m+20])\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "axes[0].scatter(trainy[:,0], trainy[:,1], marker='.', c=np.arange(trainy.shape[0]), s=1)\n",
    "axes[0].set_xlim([-m-20, m+20])\n",
    "axes[0].set_ylim([-m-20, m+20])\n",
    "\n",
    "axes[1].imshow(density, cmap=mmpy.gencmap(), extent=(xx[0], xx[-1], xx[0], xx[-1]), origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e690e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tsne(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbe426",
   "metadata": {},
   "outputs": [],
   "source": [
    "zValstr = 'zVals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6270e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the embeddings\n",
    "for i in glob.glob(parameters.projectPath+'/Projections/*_%s.mat'%(zValstr)):\n",
    "    ally = hdf5storage.loadmat(i)['zValues']\n",
    "\n",
    "m = np.abs(ally).max()\n",
    "\n",
    "sigma=2.0\n",
    "_, xx, density = mmpy.findPointDensity(ally, sigma, 610, [-m-15, m+15])\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "axes[0].scatter(ally[:,0], ally[:,1], marker='.', c=np.arange(ally.shape[0]), s=1)\n",
    "axes[0].set_xlim([-m-20, m+20])\n",
    "axes[0].set_ylim([-m-20, m+20])\n",
    "\n",
    "axes[1].imshow(density, cmap=mmpy.gencmap(), extent=(xx[0], xx[-1], xx[0], xx[-1]), origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e472fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to divide the strokes in areas\n",
    "def divide_strokes(zValues, num, origin):\n",
    "    #xs = zValues[:,0]\n",
    "    #arrx = np.linspace(xs.min(), xs.max(), num)\n",
    "    #print(origin)\n",
    "    arrx = np.linspace(origin, -origin, num)\n",
    "    #print(arrx[0])\n",
    "    #ys = zValues[:,1]\n",
    "    #arry = np.linspace(ys.min(), ys.max(), num)\n",
    "    arry = np.linspace(-origin, origin, num)\n",
    "    #print(arry)\n",
    "    return arrx, arry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to choose an stroke from the index list and return it\n",
    "def choose_stroke(lsindex):\n",
    "    import random\n",
    "    r = random.randint(0, len(lsindex)-1)\n",
    "    return lsindex[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32076e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return array of indexes of the strokes contained in a certain grid of density\n",
    "def strokes_in_area(zValues,arrx, arry, nx, ny):\n",
    "    #print(\"ZVALUES:\")\n",
    "    #print(zValues)\n",
    "    lsindex = []\n",
    "    #nx = nare\n",
    "    #ny = -1 -narea\n",
    "    upx = arrx[nx+1]\n",
    "    #print(\"upx\",upx)\n",
    "    lwx = arrx[nx]\n",
    "    #print(\"lwx\",lwx)\n",
    "    upy = arry[ny]\n",
    "    #print(\"upy\", upy)\n",
    "    lwy = arry[ny+1]\n",
    "    #print(\"lwy\", lwy)\n",
    " \n",
    "    for i in range(len(zValues)):\n",
    "        if (zValues[i][0]<=upx and zValues[i][0]>lwx and zValues[i][1]<=upy and zValues[i][1]>lwy):\n",
    "            #print(i)\n",
    "            #print(narea)\n",
    "            #print(\"arrx\",arrx[nx+1])\n",
    "            #print(\"arry\", arry[nx])\n",
    "            #print(zValues[i])\n",
    "            lsindex.append(zValues[i])\n",
    "    return lsindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b299524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot a single stroke given the index and ax in the subplot\n",
    "def plot_stroke(indx, ax):\n",
    "    trial, strokenum = list_trialstroke[indx]\n",
    "    g = D.Dat.iloc[trial][\"strokes_beh\"][strokenum]\n",
    "    strokePlots.plotDatStrokes([g],ax, clean_ordered= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f17616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get index given the array stroke\n",
    "def get_sindex(zValues, arrst):\n",
    "    indx = np.where(np.all(zValues==arrst, axis=1))\n",
    "    if len(indx[0]>1):\n",
    "        return indx[random.randint(0, len(indx)-1)][0]\n",
    "    else:\n",
    "        return indx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018749f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphin\n",
    "#fig, axes = plt.subplots(1, 1, figsize=(10,5))\n",
    "\n",
    "for i in glob.glob(parameters.projectPath+'/Projections/*_%s.mat'%(zValstr)):\n",
    "    zValues = hdf5storage.loadmat(i)['zValues']\n",
    "\n",
    "m = np.abs(zValues).max()\n",
    "\n",
    "sigma=1.\n",
    "_, xx, density = mmpy.findPointDensity(zValues, sigma, 511, [-m-15, m+15])\n",
    "\n",
    "#axes.imshow(density, cmap=mmpy.gencmap(), extent=(xx[0], xx[-1], xx[0], xx[-1]), origin='lower')\n",
    "\n",
    "#axes.axis('off')\n",
    "#axes[0].set_title('Method : %s'%parameters.method)\n",
    "\n",
    "#sc = axes.scatter([],[],marker='o', color='k', s=5)\n",
    "\n",
    "#idx = 9\n",
    "#trial,strokenum = list_trialstroke[idx]\n",
    "#s = D.Dat.iloc[trial][\"strokes_beh\"][strokenum]\n",
    "#D.plotMultStrokes([[s]])\n",
    "#fig, axes = plt.subplots(1, 1, figsize=(10,5))\n",
    "#axes.imshow(density, cmap=mmpy.gencmap(), extent=(xx[0], xx[-1], xx[0], xx[-1]), origin='lower')\n",
    "\n",
    "'''\n",
    "ax00\n",
    "ax02 x = -40, y = 60\n",
    "ax03 x = -20, y = 60\n",
    "ax04 x = 0, y = 60\n",
    "ax05\n",
    "ax06\n",
    "ax07\n",
    "ax12 x = -40, y = 40\n",
    "ax13\n",
    "\n",
    ".\n",
    ".\n",
    "ax57\n",
    "'''\n",
    "\n",
    "uplim = round((xx[-1]),-1)\n",
    "\n",
    "rows = int(uplim/10)\n",
    "dcol = int(round(rows/3))\n",
    "cols = rows +dcol\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(40,10))\n",
    "\n",
    "ax00 = plt.subplot2grid((rows,cols),(0,0),rowspan=rows, colspan=dcol)\n",
    "\n",
    "ax00.imshow(density, cmap=mmpy.gencmap(), extent=(xx[0],xx[-1],xx[0], xx[-1]), origin='lower')\n",
    "#ax00.grid()\n",
    "#print(rows)\n",
    "#print(cols)\n",
    "#print(dcol)\n",
    "arrx, arry = divide_strokes(zValues, rows+1, xx[0])\n",
    "\n",
    "ax00.set_xticks(arrx)\n",
    "ax00.set_yticks(arry)\n",
    "\n",
    "ax00.grid()\n",
    " #print(arrx)\n",
    "#print(arry)\n",
    "\n",
    "#keep calling functions to plot stuff\n",
    "for r in range(rows):\n",
    "    for c in range(dcol, cols):\n",
    "      #print(i)\n",
    "       #print(r)\n",
    "         #print(c)\n",
    "        ax = plt.subplot2grid((rows, cols,), (r,c))\n",
    "        #y = int(uplim - r*20)\n",
    "        #print(y)\n",
    "        #x = int(-uplim + (c-1)*20)\n",
    "        #print(x)\n",
    "        ls = strokes_in_area(zValues, arrx, arry, c-2, r)\n",
    "        #print(ls)\n",
    "        if (len(ls)>0):\n",
    "            st = choose_stroke(ls)\n",
    "            #print(st)\n",
    "            idx = get_sindex(zValues, st)\n",
    "            #print(idx[0])\n",
    "            plot_stroke(idx, ax)\n",
    "\n",
    "\n",
    "'''\n",
    "ax02 = plt.subplot2grid((6,8),(0,2),colspan=1)\n",
    "plot_stroke(3,ax02)\n",
    "\n",
    "ax03 = plt.subplot2grid((6,8),(0,3),colspan=1)\n",
    "plot_stroke(4,ax03)\n",
    "\n",
    "ax04 = plt.subplot2grid((6,8),(0,4),colspan=1)\n",
    "plot_stroke(13,ax04)\n",
    "\n",
    "ax05 = plt.subplot2grid((6,8),(0,5),colspan=1)\n",
    "plot_stroke(15,ax05)\n",
    "\n",
    "\n",
    "ax06 = plt.subplot2grid((6,8),(0,6),colspan=1)\n",
    "plot_stroke(17,ax06)\n",
    "\n",
    "\n",
    "ax07 = plt.subplot2grid((6,8),(0,7),colspan=1)\n",
    "plot_stroke(19,ax07)\n",
    "\n",
    "ax12 = plt.subplot2grid((6,8),(1,2),colspan=1)\n",
    "plot_stroke(23,ax13)\n",
    "'''\n",
    "plt.tight_layout()  \n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def show_stroke(z):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(10,5))\n",
    "    axes.imshow(density, cmap=mmpy.gencmap(), extent=(xx[0], xx[-1], xx[0], xx[-1]), origin='lower')\n",
    "    sc = axes.scatter([],[],marker='o', color='k', s=3)\n",
    "    idx = z\n",
    "    trial,strokenum = list_trialstroke[z]\n",
    "    s = D.Dat.iloc[trial][\"strokes_beh\"][strokenum]\n",
    "    D.plotMultStrokes([[s]])\n",
    "    sc.set_offsets(zValues[z])\n",
    "\n",
    "\n",
    "    for z in range (len(zValues)):\n",
    "        idx = z\n",
    "        trial,strokenum = list_trialstroke[z]\n",
    "        s = D.Dat.iloc[trial][\"strokes_beh\"][strokenum]\n",
    "        D.plotMultStrokes([[s]])\n",
    "        sc.set_offsets(zValues[z])\n",
    "\n",
    "\n",
    "def showing(t):    \n",
    "    for z in range(len(zValues)):\n",
    "        show_stroke(z)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#anim = VideoClip(animate, duration=2)\n",
    "#plt.close()\n",
    "#anim.ipython_display(fps=15, loop=True, autoplay=True, maxduration=120)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "h5ind = 0\n",
    "tstart = 0\n",
    "connections = [np.arange(6,10), np.arange(10,14), np.arange(14,18), np.arange(18,22), np.arange(22,26), np.arange(26,30),\n",
    "              [2,0,1],[0,3,4,5], [31,3,30]]\n",
    "\n",
    "def animate(t):\n",
    "  t = int(t*clips[h5ind].fps)+tstart\n",
    "  axes[1].clear()\n",
    "  im = axes[1].imshow(clips[h5ind].get_frame(t/clips[h5ind].fps), cmap='Greys', origin='lower')\n",
    "  for conn in connections:\n",
    "      axes[1].plot(h5s[h5ind][t, conn, 0], h5s[h5ind][t, conn, 1], 'k-')\n",
    "  axes[1].axis('off')\n",
    "  sc.set_offsets(zValues[20000*h5ind+t])\n",
    "  return mplfig_to_npimage(fig) #im, ax\n",
    "\n",
    "\n",
    "anim = VideoClip(animate, duration=2) # will throw memory error for more than 100.\n",
    "plt.close()\n",
    "anim.ipython_display(fps=15, loop=True, autoplay=True, maxduration=120)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ad07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameters.projectPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watershed things\n",
    "#modifying startsigma because 4.2 was too high\n",
    "#modifying minimum_regions because 50 was too high\n",
    "startsigma = 1.0 if parameters.method == 'TSNE' else 2.0\n",
    "mmpy.findWatershedRegions(parameters, minimum_regions=10, startsigma=startsigma, pThreshold=[0.33, 0.67],\n",
    "                     saveplot=True, endident = '*_notpca.mat')\n",
    "\n",
    "Image(glob.glob('%s/%s/zWshed*.png'%(parameters.projectPath, parameters.method))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return array of indexes of the strokes contained in a certain grid of density\n",
    "def wstrokes_in_area(zValues,wregions,nr):\n",
    "    lsindex = []\n",
    "    for i in range(len(zValues)):\n",
    "        if (wregions[i] == nr):\n",
    "            lsindex.append(zValues[i])\n",
    "    return lsindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for watershed\n",
    "import matplotlib.image as mpimg\n",
    "#from IPython.display import Image\n",
    "#Image(glob.glob('%s/%s/zWshed*.png'%(parameters.projectPath, parameters.method))[0])\n",
    "\n",
    "wshedfile = hdf5storage.loadmat('%s/%s/zVals_wShed_groups.mat'%(parameters.projectPath, parameters.method))\n",
    "\n",
    "wregions = wshedfile[\"indexesWatershedRegions\"][0]\n",
    "\n",
    "nregions = wregions.max()\n",
    "\n",
    "# calculate how many columns and rows\n",
    "# 10 rows and add more columns as needed\n",
    "# figure out how to name plot\n",
    "\n",
    "rows = 5\n",
    "dcol = int(round(rows/1))\n",
    "cols = math.ceil(nregions/rows) + dcol\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20,10))\n",
    "\n",
    "\n",
    "ax00 = plt.subplot2grid((rows,cols),(0,0),rowspan=rows, colspan=dcol)\n",
    "\n",
    "ax00.imshow(mpimg.imread(glob.glob('%s/%s/zWshed*.png'%(parameters.projectPath, parameters.method))[0]))\n",
    "ax00.axis('off')\n",
    "\n",
    "#ax00.set(xlim=(-60, 60))\n",
    "#ax00.set(ylim = (-60, 60))\n",
    "#ax00.set_xticks(arrx)\n",
    "\n",
    "#sc = ax00.scatter([],[],marker='o', color='k', s=3)\n",
    "#sc.set_offsets(zValues[9])\n",
    "\n",
    "#keep calling functions to plot stuff\n",
    "\n",
    "# for every region\n",
    "# plot one random stroke\n",
    "\n",
    "for r in range(rows):\n",
    "    for c in range(dcol, cols):\n",
    "        nr = (c-dcol)*rows + r + 1\n",
    "        ax = plt.subplot2grid((rows, cols), (r, c))\n",
    "        ls = wstrokes_in_area(zValues, wregions, nr)\n",
    "        if (len(ls)>0):\n",
    "            st = choose_stroke(ls)\n",
    "            idx = get_sindex(zValues, st)\n",
    "            plot_stroke(idx, ax)\n",
    "            ax.set_title('Region '+str(nr))\n",
    "            #ax.title()\n",
    "        \n",
    "plt.tight_layout()  \n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "#keep calling functions to plot stuff\n",
    "for r in range(rows):\n",
    "    for c in range(dcol, cols):\n",
    "      #print(i)\n",
    "       #print(r)\n",
    "         #print(c)\n",
    "        ax = plt.subplot2grid((rows, cols,), (r,c))\n",
    "        #y = int(uplim - r*20)\n",
    "        #print(y)\n",
    "        #x = int(-uplim + (c-1)*20)\n",
    "        #print(x)\n",
    "        ls = strokes_in_area(zValues, arrx, arry, c-2, r)\n",
    "        #print(ls)\n",
    "        if (len(ls)>0):\n",
    "        \n",
    "            st = choose_stroke(ls)\n",
    "            #print(st)\n",
    "            idx = get_sindex(zValues, st)\n",
    "            #print(idx[0])\n",
    "            plot_stroke(idx, ax)\n",
    "'''\n",
    "#asda\n",
    "'''\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "images = []\n",
    "for img_path in glob.glob('folder/*.png'):\n",
    "    images.append(mpimg.imread(img_path))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 5\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "    plt.imshow(image)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf19495",
   "metadata": {},
   "outputs": [],
   "source": [
    "wshedfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41616b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35dc71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af15b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293a432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
