{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amber-detection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nNOTE:\\nStuff on fitting motor programs to strokes is moved to :\\n\"stroke_to_MP_scor...\"\\n\\nHere is testing parsing, generally from images, mostly based on pyBPL tutorials.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "NOTE:\n",
    "Stuff on fitting motor programs to strokes is moved to :\n",
    "\"stroke_to_MP_scor...\"\n",
    "\n",
    "Here is testing parsing, generally from images, mostly based on pyBPL tutorials.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "SDIR = \"/data2/analyses/database/expts/Red-lines5-formodeling-210309_102050\"\n",
    "\n",
    "with open(f\"{SDIR}/dat.pkl\", \"rb\") as f:\n",
    "    dat = pickle.load(f)\n",
    "with open(f\"{SDIR}/metadat.pkl\", \"rb\") as f:\n",
    "    metadat = pickle.load(f)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SET THESE PARAMS\n",
    "\n",
    "# Are you trying to parse ground truth images (that monkey saw) or the image resulting from onkey beahvior?\n",
    "if True:\n",
    "    stim_ver = \"task_image\" # stimulus monkey saw\n",
    "else:\n",
    "    stim_ver = \"monkey_strokes\" # drawing produced by monkey\n",
    "    \n",
    "    \n",
    "# == coordinates of the sketchpad used by monkey\n",
    "# max width or hiegh (whichever one greater), num pixels for\n",
    "# half of page, so that sketchpad will be square with edges in \n",
    "# both dimensions of : (-WH, WH)\n",
    "canvas_max_WH = np.max(np.abs(metadat[\"sketchpad_edges\"])) # smallest square that bounds all the stimuli\n",
    "\n",
    "# == coordinates that BPL parsing wants\n",
    "# num pixels per dimension for the output image\n",
    "image_WH = 105 # I think 105 is used for pyBPL. CONFIRM THIS.\n",
    "\n",
    "# Get example stimulus (for tutorial purpose).\n",
    "import random\n",
    "ind = random.randint(0, len(dat)-1)\n",
    "if stim_ver==\"task_image\":\n",
    "    strokes = dat[\"strokes_task\"].values[ind] # in same format as behavior 'strokes'\n",
    "elif stim_ver==\"monkey_strokes\":\n",
    "    strokes = dat[\"strokes_beh\"].values[ind] # in same format as behavior 'strokes'\n",
    "else:\n",
    "    assert False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == CONVERT TASK INTO BINARY IMAGE\n",
    "from pythonlib.drawmodel.primitives import prog2pxl\n",
    "from pythonlib.drawmodel.strokePlots import plotDatStrokes\n",
    "\n",
    "I = prog2pxl(strokes, WHdraw=canvas_max_WH*2, WH=image_WH, smoothing=1)\n",
    "I = np.array(I>0.5) # binarize\n",
    "\n",
    "# ----- PLOTS\n",
    "# plot strokes\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plotDatStrokes(strokes, ax, each_stroke_separate=True)\n",
    "\n",
    "# plot hist of values\n",
    "plt.figure()\n",
    "plt.hist(I[:], log=True)\n",
    "\n",
    "# plot\n",
    "plt.figure()\n",
    "plt.imshow(I, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.title(\"after binarize\")\n",
    "\n",
    "print(I.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section deals with issue that corners are in general not used as junctions in \n",
    "# the undirected graph that represents the drawing during parsing.\n",
    "# For monkey, they often break down L-shaped things into two lines, so we want to consider\n",
    "# parses where corners can have a junction.\n",
    "\n",
    "# Solution: determine coordinates of all \"segment\" endpoints, which will generally include\n",
    "# corners (since things like L's are represnted as two lines usually). \n",
    "# Will just pass in all endpoints, since anything that is redundant with the \n",
    "# BPL junctions will be automaticalyl discarded.\n",
    "\n",
    "if stim_ver==\"task_image\":\n",
    "    from pythonlib.drawmodel.image import convStrokecoordToImagecoord\n",
    "\n",
    "    sketchpad_edges = np.array([[-canvas_max_WH, canvas_max_WH], [-canvas_max_WH, canvas_max_WH]])\n",
    "    image_edges = np.array([[1, image_WH-1], [1, image_WH-1]]) # 1 on edges, since there is a slight border.\n",
    "\n",
    "    extra_junctions = []\n",
    "    for pts in strokes:\n",
    "        pts_image_inds = convStrokecoordToImagecoord(pts, sketchpad_edges, image_edges)\n",
    "        extra_junctions.append(pts_image_inds[0])\n",
    "        extra_junctions.append(pts_image_inds[-1])\n",
    "\n",
    "    extra_junctions = np.stack(extra_junctions, axis=0)\n",
    "    print(extra_junctions)\n",
    "elif stim_ver==\"monkey_strokes\":\n",
    "    # then dont need to do this, since if monkey raises finger at corner, that will be\n",
    "    # detected by BPL, since it will not be a perfectly clean corner, and so will\n",
    "    # be considered a \"cross\". [have not verified this by testing]\n",
    "    pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PARSE USING PYBPL\n",
    "from pybpl.matlab.bottomup import generate_random_parses\n",
    "\n",
    "# generate random parses\n",
    "parses = generate_random_parses(I, seed=3, max_ntrials=150, max_nwalk=150,\n",
    "                                        max_nstroke=100, ver=\"lucas\", \n",
    "                                        extra_junctions=extra_junctions)\n",
    "# parses = generate_random_parses(img, seed=3, ver=\"lucas\")\n",
    "# parses = generate_random_parses(img, seed=3,max_ntrials=150, max_nwalk=150,\n",
    "#                                         max_nstroke=100, ver=\"reuben\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-damages",
   "metadata": {},
   "source": [
    "### RUNNING EXAMPLES FROM PYBPL AND PLYING AROUND WITH IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_dir = \"/data1/code/python/pyBPL/examples/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-complexity",
   "metadata": {},
   "source": [
    "###  examples/parse_image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from pybpl.util import dist_along_traj\n",
    "from pybpl.matlab.bottomup import generate_random_parses\n",
    "\n",
    "\n",
    "\n",
    "def plot_stroke(ax, stk, color, lw=2):\n",
    "    if len(stk) > 1 and dist_along_traj(stk) > 0.01:\n",
    "        ax.plot(stk[:,0], -stk[:,1], color=color, linewidth=lw)\n",
    "    else:\n",
    "        ax.plot(stk[0,0], -stk[0,1], color=color, linewidth=lw, marker='.')\n",
    "\n",
    "def plot_parse(ax, strokes, lw=2):\n",
    "    ns = len(strokes)\n",
    "    colors = ['r','g','b','m','c']\n",
    "    for i in range(ns):\n",
    "        plot_stroke(ax, strokes[i], colors[i], lw)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(0,105)\n",
    "    ax.set_ylim(105,0)\n",
    "\n",
    "def main():\n",
    "    # load image to numpy binary array\n",
    "    img = imageio.imread(f\"{examples_dir}./image_H.jpg\")\n",
    "    img = np.array(img > 200)\n",
    "\n",
    "    # generate random parses\n",
    "    parses = generate_random_parses(img, seed=3)\n",
    "\n",
    "    # plot parsing results\n",
    "    nparse = len(parses)\n",
    "    n = math.ceil(nparse/10)\n",
    "    m = 10\n",
    "    fig, axes = plt.subplots(n,m+1,figsize=(m+1, n))\n",
    "    # first column\n",
    "    axes[0,0].imshow(img, cmap=plt.cm.binary)\n",
    "    axes[0,0].set_xticks([]); axes[0,0].set_yticks([])\n",
    "    axes[0,0].set_title('Input')\n",
    "    for i in range(1,n):\n",
    "        axes[i,0].set_axis_off()\n",
    "    # remaining_columns\n",
    "    for i in range(n):\n",
    "        for j in range(1,m+1):\n",
    "            ix = i*m + (j-1)\n",
    "            if ix >= nparse:\n",
    "                axes[i,j].set_axis_off()\n",
    "                continue\n",
    "            plot_parse(axes[i,j], parses[ix])\n",
    "    plt.subplots_adjust(hspace=0., wspace=0.)\n",
    "    plt.show()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-morning",
   "metadata": {},
   "source": [
    "### examples.generate_character.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-panama",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pybpl.library import Library\n",
    "from pybpl.model import CharacterModel\n",
    "\n",
    "\n",
    "def display_type(c):\n",
    "    print('----BEGIN CHARACTER TYPE INFO----')\n",
    "    print('num strokes: %i' % c.k)\n",
    "    for i in range(c.k):\n",
    "        print('Stroke #%i:' % i)\n",
    "        print('\\tsub-stroke ids: ', list(c.part_types[i].ids.numpy()))\n",
    "        print('\\trelation category: %s' % c.relation_types[i].category)\n",
    "    print('----END CHARACTER TYPE INFO----')\n",
    "\n",
    "def main():\n",
    "    print('generating character...')\n",
    "    lib = Library(use_hist=True)\n",
    "    model = CharacterModel(lib)\n",
    "    fig, axes = plt.subplots(nrows=10, ncols=3, figsize=(1.5, 5))\n",
    "    for i in range(10):\n",
    "        ctype = model.sample_type()\n",
    "        ll = model.score_type(ctype)\n",
    "        print('type %i' % i)\n",
    "        display_type(ctype)\n",
    "        print('log-likelihood: %0.2f \\n' % ll.item())\n",
    "        # sample a few character tokens and visualize them\n",
    "        for j in range(3):\n",
    "            ctoken = model.sample_token(ctype)\n",
    "            img = model.sample_image(ctoken)\n",
    "            axes[i,j].imshow(img, cmap='Greys')\n",
    "            axes[i,j].tick_params(\n",
    "                which='both',\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                labelbottom=False,\n",
    "                labelleft=False\n",
    "            )\n",
    "        axes[i,0].set_ylabel('%i' % i, fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-contents",
   "metadata": {},
   "source": [
    "### examples/optimize_type.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sample a character type and then optimize its parameters to maximize the\n",
    "likelihood of the type under the prior\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pybpl.library import Library\n",
    "from pybpl.model import CharacterModel\n",
    "from pybpl.objects import CharacterType\n",
    "\n",
    "\n",
    "\n",
    "def optimize_type(model, c, lr, nb_iter, eps, show_examples=True):\n",
    "    \"\"\"\n",
    "    Take a character type and optimize its parameters to maximize the\n",
    "    likelihood under the prior, using gradient descent\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : CharacterModel\n",
    "    c : CharacterType\n",
    "    lr : float\n",
    "    nb_iter : int\n",
    "    eps : float\n",
    "    show_examples : bool\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score_list : list of float\n",
    "\n",
    "    \"\"\"\n",
    "    # round nb_iter to nearest 10\n",
    "    nb_iter = np.round(nb_iter, -1)\n",
    "    # get optimizable variables & their bounds\n",
    "    c.train()\n",
    "    params = c.parameters()\n",
    "    lbs = c.lbs(eps)\n",
    "    ubs = c.ubs(eps)\n",
    "    # optimize the character type\n",
    "    score_list = []\n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "    if show_examples:\n",
    "        fig, axes = plt.subplots(10, 4, figsize=(4, 10))\n",
    "    interval = int(nb_iter / 10)\n",
    "    for idx in range(nb_iter):\n",
    "        if idx % interval == 0:\n",
    "            # print optimization progress\n",
    "            print('iteration #%i' % idx)\n",
    "            if show_examples:\n",
    "                # sample 4 tokens of current type (for visualization)\n",
    "                for i in range(4):\n",
    "                    token = model.sample_token(c)\n",
    "                    img = model.sample_image(token)\n",
    "                    axes[idx//interval, i].imshow(img, cmap='Greys')\n",
    "                    axes[idx//interval, i].tick_params(\n",
    "                        which='both',\n",
    "                        bottom=False,\n",
    "                        left=False,\n",
    "                        labelbottom=False,\n",
    "                        labelleft=False\n",
    "                    )\n",
    "                axes[idx//interval, 0].set_ylabel('%i' % idx)\n",
    "        # zero optimizer gradients\n",
    "        optimizer.zero_grad()\n",
    "        # compute log-likelihood of the token\n",
    "        score = model.score_type(c)\n",
    "        score_list.append(score.item())\n",
    "        # gradient descent step (minimize loss)\n",
    "        loss = -score\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # project all parameters into allowable range\n",
    "        with torch.no_grad():\n",
    "            for param, lb, ub in zip(params, lbs, ubs):\n",
    "                if lb is not None:\n",
    "                    torch.max(param, lb, out=param)\n",
    "                if ub is not None:\n",
    "                    torch.min(param, ub, out=param)\n",
    "\n",
    "    return score_list\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--ns', required=False, type=int,\n",
    "                        help=\"number of strokes\")\n",
    "    parser.add_argument('--lr', default=1e-3, type=float,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--eps', default=1e-4, type=float,\n",
    "                        help='tolerance for constrained optimization')\n",
    "    parser.add_argument('--nb_iter', default=1000, type=int,\n",
    "                        help='number of optimization iterations')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # load the library\n",
    "    lib = Library()\n",
    "    # create the BPL graphical model\n",
    "    model = CharacterModel(lib)\n",
    "\n",
    "    # sample a character type\n",
    "    c = model.sample_type(k=args.ns)\n",
    "    print('num strokes: %i' % c.k)\n",
    "    print('num sub-strokes: ', [p.nsub.item() for p in c.part_types])\n",
    "\n",
    "    # optimize the character type that we sampled\n",
    "    score_list = optimize_type(model, c, args.lr, args.nb_iter, args.eps)\n",
    "\n",
    "    # plot log-likelihood vs. iteration\n",
    "    plt.figure()\n",
    "    plt.plot(score_list)\n",
    "    plt.ylabel('log-likelihood')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-humanity",
   "metadata": {},
   "source": [
    "## LOAD PRE-TRAINED MODEL (README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybpl.library import Library\n",
    "from pybpl.model import CharacterModel\n",
    "\n",
    "# load the hyperparameters of the BPL graphical model (i.e. the \"library\")\n",
    "\n",
    "lib = Library(use_hist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the BPL graphical model\n",
    "model = CharacterModel(lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a character type from the prior P(Type) and score its log-probability\n",
    "char_type = model.sample_type()\n",
    "ll_type = model.score_type(char_type)\n",
    "\n",
    "# sample a character token from P(Token | Type=type) and score its log-probability\n",
    "char_token = model.sample_token(char_type)\n",
    "ll_token_given_type = model.score_token(char_type, char_token)\n",
    "\n",
    "# sample an image from P(Image | Token=token)\n",
    "image = model.sample_image(char_token)\n",
    "ll_image_given_token = model.score_image(char_token, image)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "# plt.title(ll_image_given_token)\n",
    "\n",
    "print(ll_type, ll_token_given_type, ll_image_given_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "## === scoring\n",
    "model.score_image(ctok, image)\n",
    "model.score_token(cto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctype = model.sample_type()\n",
    "ctok = model.sample_token(ctype)\n",
    "pimg = model.get_pimg(ctok)\n",
    "plt.figure()\n",
    "plt.imshow(pimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.type_dist.sample_part_type(torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.type_dist.sample_part_type(torch.tensor(2))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_type.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-relation",
   "metadata": {},
   "source": [
    "## ===== FIT IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybpl.model.model import fit_image\n",
    "from pybpl.library import Library\n",
    "lib = Library(use_hist=False)\n",
    "fit_image(image, lib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-jurisdiction",
   "metadata": {},
   "source": [
    "### LOAD character model and play around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = Library(use_hist=True)\n",
    "model = CharacterModel(lib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctype = model.sample_type()\n",
    "model.score_type(ctype)\n",
    "ctoken = model.sample_token(ctype)\n",
    "img = model.sample_image(ctoken)\n",
    "plt.figure()\n",
    "plt.imshow(img, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.token_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score_image(ctoken, img)\n",
    "model.score_token(ctype, ctoken)\n",
    "dir(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
